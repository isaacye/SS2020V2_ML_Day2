{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SS20_lab3_LR_MLPg_skeleton.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isaacye/SS2020V2_ML_Day2/blob/master/Session_3/SS20_lab3_LR_MLPg_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YokuGQf-_w9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsCk9Jrh_QBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6q1QnMK_UCV",
        "colab_type": "text"
      },
      "source": [
        "##**Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0aNL9wm_SS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_data = 2400\n",
        "x1 = np.random.rand(num_data) *10\n",
        "x2 = np.random.rand(num_data) *10\n",
        "e = np.random.normal(0, 0.5, num_data)\n",
        "X= np.array([x1,x2]).T  # T for transpose from (2, 2400) to (2400, 2)\n",
        "y=2*np.sin(x1) + np.log(0.5*x2**2)+e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iAcmku3_grY",
        "colab_type": "text"
      },
      "source": [
        "Data split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQArWOcd_bB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X, train_y = X[:1600, :], y[:1600]\n",
        "val_X, val_y = X[1600:2000, :], y[1600:2000]\n",
        "test_X, test_y = X[2000:, :], y[2000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xllKg8m2_thf",
        "colab_type": "text"
      },
      "source": [
        "##**Visualizating input data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvtdLcT9_jX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(12,5))\n",
        "\n",
        "ax1 = fig.add_subplot(1, 3, 1, projection='3d') # size 1 row, 3 col, location 1\n",
        "ax1.scatter(train_X[:, 0], train_X[:, 1], train_y, c=train_y, cmap='jet')\n",
        "\n",
        "ax1.set_xlabel('x1')\n",
        "ax1.set_ylabel('x2')\n",
        "ax1.set_zlabel('y')\n",
        "ax1.set_title('Train Set Distribution')\n",
        "ax1.set_zlim(-10, 6)  # z axis limit\n",
        "ax1.view_init(40, -60) #view angle\n",
        "ax1.invert_xaxis() #direction of number line\n",
        "\n",
        "ax2 = fig.add_subplot(1, 3, 2, projection='3d')\n",
        "ax2.scatter(val_X[:, 0], val_X[:, 1], val_y, c=val_y, cmap='jet')\n",
        "\n",
        "ax2.set_xlabel('x1')\n",
        "ax2.set_ylabel('x2')\n",
        "ax2.set_zlabel('y')\n",
        "ax2.set_title('Validation Set Distribution')\n",
        "ax2.set_zlim(-10, 6)\n",
        "ax2.view_init(40, -60)\n",
        "ax2.invert_xaxis()\n",
        "\n",
        "ax3 = fig.add_subplot(1, 3, 3, projection='3d')\n",
        "ax3.scatter(test_X[:, 0], test_X[:, 1], test_y, c=test_y, cmap='jet')\n",
        "\n",
        "ax3.set_xlabel('x1')\n",
        "ax3.set_ylabel('x2')\n",
        "ax3.set_zlabel('y')\n",
        "ax3.set_title('Test Set Distribution')\n",
        "ax3.set_zlim(-10, 6)\n",
        "ax3.view_init(40, -60)\n",
        "ax3.invert_xaxis()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jTYutV4_5Zt",
        "colab_type": "text"
      },
      "source": [
        "##**Model(Hypothesis) Define**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVYLR6Li_yOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLPModel(nn.Module):\n",
        "    def __init__(self): \n",
        "        super(MLPModel, self).__init__()\n",
        "        self.linear1 = nn.Linear(in_features=2, out_features=200)\n",
        "        self.linear2 = nn.Linear(in_features=200, out_features=1)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.linear2(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MswJsqaAByN",
        "colab_type": "text"
      },
      "source": [
        "##**Cost(Loss) Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kZrTxdf_9t1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reg_loss = nn.MSELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2qe7y8MexuO",
        "colab_type": "text"
      },
      "source": [
        "# **Checking GPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7FR2w6ju6w1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K8P7kZ2AI8g",
        "colab_type": "text"
      },
      "source": [
        "#**Training & Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zEAqT6xAFe0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "# ====== Model selection ======= #\n",
        "model = MLPModel()\n",
        "\n",
        "# ====== GPU selection ======= #\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "lr = 0.005\n",
        "optimizer = optim.SGD(model.parameters(), lr =lr)  # model.parameters : W, b of linear model\n",
        "\n",
        "list_epoch = []\n",
        "list_train_loss = []\n",
        "list_val_loss = []\n",
        "list_mae = []\n",
        "list_mae_epoch = []\n",
        "\n",
        "epoch = 4000\n",
        "\n",
        "for i in range(epoch):\n",
        "  # ===== Training ===== #\n",
        "  model.train() #setting mode for model train\n",
        "  optimizer.zero_grad() # initialize gradient\n",
        "\n",
        "  input_x = torch.Tensor(train_X)\n",
        "  true_y = torch.Tensor(train_y)\n",
        "\n",
        "  # ===== GPU ===== # \n",
        "\n",
        "\n",
        "\n",
        "  pred_y = model(input_x)\n",
        "\n",
        "  loss = reg_loss(pred_y.squeeze(), true_y) # dropping column of pred_y dimession\n",
        "  loss.backward() # backward() calculate gradients\n",
        "  optimizer.step() # update gradients using step()\n",
        "  list_epoch.append(i)\n",
        "\n",
        "  # ===== GPU ===== #\n",
        "\n",
        "\n",
        "\n",
        "  # ===== Validation ===== #\n",
        "  model.eval()\n",
        "  optimizer.zero_grad()\n",
        "  input_x = torch.Tensor(val_X)\n",
        "  true_y = torch.Tensor(val_y)\n",
        "   \n",
        "  # ===== GPU ===== #  \n",
        "\n",
        "      \n",
        "  pred_y = model(input_x)\n",
        "\n",
        "  loss = reg_loss(pred_y.squeeze(), true_y)\n",
        "\n",
        "  # ===== GPU ===== #\n",
        "\n",
        "\n",
        "  # ====== Evaluation ======= #\n",
        "  \n",
        "  if i % 200 == 0: # evaluate it every 200\n",
        "        \n",
        "        # ====== Calculate MAE ====== #\n",
        "        model.eval()\n",
        "        optimizer.zero_grad()\n",
        "        input_x = torch.Tensor(test_X)\n",
        "        true_y = torch.Tensor(test_y)\n",
        "\n",
        "        # ===== GPU ===== #        \n",
        "        if device != 'cpu':\n",
        "         \n",
        "\n",
        "        else:\n",
        "            pred_y = model(input_x).detach().numpy()\n",
        "            mae = mean_absolute_error(true_y, pred_y) \n",
        "\n",
        "        list_mae.append(mae)\n",
        "        list_mae_epoch.append(i)\n",
        "        \n",
        "        fig = plt.figure(figsize=(15,5))\n",
        "        \n",
        "        # ====== True Y Scattering ====== #\n",
        "        ax1 = fig.add_subplot(1, 3, 1, projection='3d')\n",
        "        ax1.scatter(test_X[:, 0], test_X[:, 1], test_y, c=test_y, cmap='jet')\n",
        "        \n",
        "        ax1.set_xlabel('x1')\n",
        "        ax1.set_ylabel('x2')\n",
        "        ax1.set_zlabel('y')\n",
        "        ax1.set_zlim(-10, 6)\n",
        "        ax1.view_init(40, -40)\n",
        "        ax1.set_title('True test y')\n",
        "        ax1.invert_xaxis()\n",
        "\n",
        "        # ====== Predicted Y Scattering ====== #\n",
        "        ax2 = fig.add_subplot(1, 3, 2, projection='3d')\n",
        "        ax2.scatter(test_X[:, 0], test_X[:, 1], pred_y, c=pred_y[:,0], cmap='jet')\n",
        "\n",
        "        ax2.set_xlabel('x1')\n",
        "        ax2.set_ylabel('x2')\n",
        "        ax2.set_zlabel('y')\n",
        "        ax2.set_zlim(-10, 6)\n",
        "        ax2.view_init(40, -40)\n",
        "        ax2.set_title('Predicted test y')\n",
        "        ax2.invert_xaxis()\n",
        "\n",
        "        # ====== Just for Visualizaing with High Resolution ====== #\n",
        "        input_x = torch.Tensor(train_X)\n",
        "        \n",
        "        # ===== GPU ===== #\n",
        "        if device != 'cpu':\n",
        "\n",
        "        else:\n",
        "            pred_y = model(input_x).detach().numpy()\n",
        "        \n",
        "        ax3 = fig.add_subplot(1, 3, 3, projection='3d')\n",
        "        ax3.scatter(train_X[:, 0], train_X[:, 1], pred_y, c=pred_y[:,0], cmap='jet')\n",
        "\n",
        "        ax3.set_xlabel('x1')\n",
        "        ax3.set_ylabel('x2')\n",
        "        ax3.set_zlabel('y')\n",
        "        ax3.set_zlim(-10, 6)\n",
        "        ax3.view_init(40, -40)\n",
        "        ax3.set_title('Predicted train y')\n",
        "        ax3.invert_xaxis()\n",
        "        \n",
        "        plt.show()\n",
        "        print(i, loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZAsR0EJAXKS",
        "colab_type": "text"
      },
      "source": [
        "##**Presenting loss and error**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-u1yTm-ATqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(15,5))\n",
        "\n",
        "# ====== Loss Fluctuation ====== #\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "ax1.plot(list_epoch, list_train_loss, label='train_loss')\n",
        "ax1.plot(list_epoch, list_val_loss, '--', label='val_loss')\n",
        "ax1.set_xlabel('epoch')\n",
        "ax1.set_ylabel('loss')\n",
        "ax1.set_ylim(0, 5)\n",
        "ax1.grid()\n",
        "ax1.legend()\n",
        "ax1.set_title('epoch vs loss')\n",
        "\n",
        "# ====== Metric Fluctuation ====== #\n",
        "ax2 = fig.add_subplot(1, 2, 2)\n",
        "ax2.plot(list_mae_epoch, list_mae, marker='x', label='mae metric')\n",
        "\n",
        "ax2.set_xlabel('epoch')\n",
        "ax2.set_ylabel('mae')\n",
        "ax2.grid()\n",
        "ax2.legend()\n",
        "ax2.set_title('epoch vs mae')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}